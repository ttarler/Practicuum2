\BOOKMARK [1][-]{section*.3}{Theory}{}% 1
\BOOKMARK [2][-]{section*.4}{Reinforcement Learning}{section*.3}% 2
\BOOKMARK [2][-]{section*.5}{Deep Q-Networks}{section*.3}% 3
\BOOKMARK [2][-]{section*.6}{Deep Deterministic Policy Networks}{section*.3}% 4
\BOOKMARK [1][-]{section*.7}{Bipedal Walker}{}% 5
\BOOKMARK [1][-]{section*.9}{Results}{}% 6
\BOOKMARK [2][-]{section*.10}{Methodology}{section*.9}% 7
\BOOKMARK [2][-]{section*.11}{DQN}{section*.9}% 8
\BOOKMARK [3][-]{figure.caption.16}{1000 Episodes}{section*.11}% 9
\BOOKMARK [3][-]{figure.caption.20}{5000 Episodes}{section*.11}% 10
\BOOKMARK [2][-]{section*.21}{DDPG}{section*.9}% 11
\BOOKMARK [3][-]{figure.caption.28}{1000 Episodes}{section*.21}% 12
\BOOKMARK [3][-]{figure.caption.31}{5000 Episodes}{section*.21}% 13
\BOOKMARK [2][-]{section*.32}{Comparison of DQN vs. DDPG}{section*.9}% 14
\BOOKMARK [1][-]{section*.33}{Concluding Remarks}{}% 15
\BOOKMARK [1][-]{section*.34}{References}{}% 16
