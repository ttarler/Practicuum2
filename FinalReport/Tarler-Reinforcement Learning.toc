\contentsline {section}{Theory}{5}{section*.3}%
\contentsline {subsection}{Reinforcement Learning}{5}{section*.4}%
\contentsline {subsection}{Deep Q-Networks}{6}{section*.5}%
\contentsline {subsection}{Deep Deterministic Policy Networks}{8}{section*.6}%
\contentsline {section}{Bipedal Walker}{11}{section*.7}%
\contentsline {section}{Results}{13}{section*.9}%
\contentsline {subsection}{Methodology}{13}{section*.10}%
\contentsline {subsection}{DQN}{13}{section*.11}%
\contentsline {subsubsection}{1000 Episodes}{15}{figure.caption.16}%
\contentsline {subsubsection}{5000 Episodes}{16}{figure.caption.20}%
\contentsline {subsection}{DDPG}{18}{section*.21}%
\contentsline {subsubsection}{1000 Episodes}{23}{figure.caption.28}%
\contentsline {subsubsection}{5000 Episodes}{24}{figure.caption.31}%
\contentsline {subsection}{Comparison of DQN vs. DDPG}{26}{section*.32}%
\contentsline {section}{Concluding Remarks}{27}{section*.33}%
\contentsline {section}{References}{29}{section*.34}%
